{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "168fdc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor                  \n",
    "import torch.nn as nn                     \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from tqdm import tqdm\n",
    "print(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d4b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNLE(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() \n",
    "              \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)]).to(device)\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "    def forward(self,x):\n",
    "            if torch.is_tensor(x) !=True:\n",
    "                x= torch.from_numpy(x).to(device)\n",
    "            sigma = x.type(torch.DoubleTensor).to(device)\n",
    "            for i in range(len(layers)-2):\n",
    "                z = self.linears[i](sigma)\n",
    "                sigma = self.activation(z)\n",
    "            sigma = self.linears[-1](sigma)\n",
    "            return sigma\n",
    "    \n",
    "    #Modify the loss function as per the problem\n",
    "    def loss_func(self, x_train):        \n",
    "             \n",
    "        g = x_train.clone()\n",
    "                        \n",
    "        g.requires_grad = True\n",
    "        \n",
    "        u = self.forward(g)\n",
    "        eqn1,eqn2 = eqn(u,x_train)\n",
    "        loss_f1 = self.loss_function(eqn1,torch.tensor(0).type(torch.DoubleTensor).to(device))\n",
    "        loss_f2 = self.loss_function(eqn2,torch.tensor(0).type(torch.DoubleTensor).to(device))\n",
    "        return loss_f1+loss_f2 \n",
    "    \n",
    "    def closure(self,steps,eps=1e-8,lr=1e-2,show=True):\n",
    "            start = time.time()\n",
    "            optimizer = torch.optim.Adam(inn.parameters(),lr=lr)\n",
    "            for i in tqdm(range(steps)):\n",
    "                loss = self.loss_func(x_train)\n",
    "                self.mse = loss\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #Learning rate scheduling. It performs better using this even for Adam.\n",
    "                if i%(steps/4)==0:\n",
    "                    lr=lr/5\n",
    "                    optimizer = torch.optim.Adam(inn.parameters(),lr=lr)\n",
    "                    if show==True:\n",
    "                        with torch.no_grad():\n",
    "                            print('Iter: ',i,'Loss: ',loss.detach().cpu().numpy(),' lr: ',lr)\n",
    "                if self.mse<=eps:\n",
    "                    print('Converged !')\n",
    "                    break\n",
    "            print('MSE Loss: ',float(self.mse.detach().cpu()))\n",
    "            print('total time: ',time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1342c155",
   "metadata": {},
   "source": [
    "# Equations :\n",
    "$$x^3+ay^2+b=0\\\\y^3+cx+d=0$$ <br>We aim to find roots (x,y) as a function of a,b,c,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7902cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eqn(u,x_train):\n",
    "    x = u[:,[0]]\n",
    "    y= u[:,[1]]\n",
    "    a=x_train[:,[0]]\n",
    "    b=x_train[:,[1]]\n",
    "    c=x_train[:,[2]]\n",
    "    d=x_train[:,[3]]\n",
    "    return (x**3+a*y**2+b),(y**3+c*x+d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6239c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6250000, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.linspace(-1,1,50)\n",
    "b = np.linspace(-1,1,50)\n",
    "c = np.linspace(-1,1,50)\n",
    "d = np.linspace(-1,1,50)\n",
    "\n",
    "A,B,C,D = np.meshgrid(a,b,c,d)\n",
    "x_train = torch.from_numpy(np.hstack(( A.flatten()[:,None],B.flatten()[:,None],\n",
    "                                      C.flatten()[:,None],\n",
    "                                      D.flatten()[:,None]))).to(device)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ffb7e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]/home/djc/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([6250000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  0%|                                       | 1/10000 [00:00<2:18:02,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  0 Loss:  0.6410734004533946  lr:  0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████                           | 2501/10000 [27:30<1:22:29,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  2500 Loss:  0.48756017135449436  lr:  0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████                   | 5001/10000 [54:59<55:06,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  5000 Loss:  0.001651383027345114  lr:  0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████         | 7501/10000 [1:22:32<27:19,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  7500 Loss:  0.0009994071354628578  lr:  0.00016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10000/10000 [1:50:02<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss:  0.0007202511308959526\n",
      "total time:  6602.348175048828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "steps=10000\n",
    "layers = np.array([4,50,50,50,50,2])\n",
    "inn = SNLE(layers)\n",
    "inn.to(device)\n",
    "inn.closure(steps=steps,show=True,lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72fde21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7830, -0.7431],\n",
      "         [ 0.6653,  0.8684],\n",
      "         [-1.0024,  1.0326],\n",
      "         [-0.2743,  0.7591]]], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test=np.array([[0.5,0.2,0.6,0.9],[0.4,-0.6,0.2,-0.8],[0.2,0.8,0.5,-0.6],[-0.5,0.3,0.8,-0.2]])[None,:]\n",
    "print(inn(test))#roots (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e9dd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
